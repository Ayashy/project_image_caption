{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from datasets import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "data_folder = os.path.join('processed_data','flickr')\n",
    "embedding_len = 512  \n",
    "attention_len = 512  \n",
    "lstm_len = 512  \n",
    "caps_per_image=2\n",
    "batch_size = 32\n",
    "learning_rate = 4e-3  \n",
    "\n",
    "# Read word map\n",
    "word_map_file = os.path.join(data_folder, 'WORDMAP.json')\n",
    "with open(word_map_file, 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "\n",
    "# Decoder model\n",
    "decoder = Decoder(attention_len=attention_len,\n",
    "                    embedding_len=embedding_len,\n",
    "                    features_len=lstm_len,\n",
    "                    wordmap_len=len(word_map))\n",
    "# We need an optimiser to update the model weights\n",
    "grad_params=filter(lambda p: p.requires_grad, decoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(params=grad_params, lr=learning_rate)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Dataloaders are wrappers around datasets that help woth the learning.\n",
    "# Its not mandatory but its usefull so we might as well use it\n",
    "dataset=FlickrDataset(data_folder, 'DEV', caps_per_image)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "            FlickrDataset(data_folder, 'DEV', caps_per_image),\n",
    "            batch_size=5, )\n",
    "\n",
    "losses=[]\n",
    "weights=[]\n",
    "predictions=[]\n",
    "print('--------------------------------------------- LEARNING STARTED -------------------------------------------')\n",
    "for epoch in range(1,50):\n",
    "    print( '----------------------------------- Epoch',epoch,'----------------------------------')\n",
    "    for i,(imgs,caps,caplens) in enumerate(data_loader):\n",
    "        caption=''\n",
    "        for line in caps[0]:\n",
    "            for key in word_map.keys():\n",
    "                if word_map[key]==line:\n",
    "                    caption+=' '+str(key)\n",
    "        print(imgs[0],caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- LEARNING STARTED -------------------------------------------\n",
      "----------------------------------- Epoch 1 ----------------------------------\n",
      "Loss :  tensor(8.0659, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(7.4355, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(6.5148, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(5.2993, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(5.9644, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(6.4915, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(6.0818, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(4.8781, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a in in in the in <end> <end> <end> <end> <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 2 ----------------------------------\n",
      "Loss :  tensor(4.6901, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(4.3073, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.9062, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.7140, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(4.0513, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(4.4262, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(4.4263, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.7345, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a a dog dog dog dog dog dog snow dog snow dog\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 3 ----------------------------------\n",
      "Loss :  tensor(3.8989, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.6900, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.6272, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.2018, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.5016, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.8400, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.7850, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.0096, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a dog dog dog a dog a <end> <end> <end> <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 4 ----------------------------------\n",
      "Loss :  tensor(3.2202, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.2840, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.2931, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.9039, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.1877, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.2971, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.3808, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.6080, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown brown brown dog a beach <end> <end> <end> <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 5 ----------------------------------\n",
      "Loss :  tensor(2.6638, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.8656, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.8305, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.5165, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.7223, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(3.1078, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.8961, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.1813, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown dog dog dog dog <end> <end> <end> <end> <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 6 ----------------------------------\n",
      "Loss :  tensor(2.3762, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.4871, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.5132, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.2962, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.1862, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.5550, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.5537, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.9498, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown brown dog dog a beach beach beach beach beach <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 7 ----------------------------------\n",
      "Loss :  tensor(2.1715, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.0323, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.2442, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.1262, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.9570, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.2086, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.5219, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7718, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown dog a a a <end> <end> <end> <end> <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 8 ----------------------------------\n",
      "Loss :  tensor(2.0846, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.0703, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.1870, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.9883, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.5512, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.2218, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.3324, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.6763, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown brown dog dog a a running <end> <end> <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 9 ----------------------------------\n",
      "Loss :  tensor(2.1184, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7663, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.0362, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.8219, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.4767, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.0345, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.3904, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.5548, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown dog a a a collar beach beach beach beach <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 10 ----------------------------------\n",
      "Loss :  tensor(2.2300, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.8967, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.9304, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7967, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.6435, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.1118, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.2145, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.4821, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown dog is running running running running <end> <end> <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 11 ----------------------------------\n",
      "Loss :  tensor(2.0837, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.0264, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.0549, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.8717, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.4532, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.0816, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.2518, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.5462, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown dog dog wearing a a a beach beach beach beach\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 12 ----------------------------------\n",
      "Loss :  tensor(2.0754, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.9254, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.9224, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.8155, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.5713, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.9918, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.1223, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.5004, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown dog running running running running <end> <end> <end> <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 13 ----------------------------------\n",
      "Loss :  tensor(1.9251, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.6356, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.8827, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7992, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.5637, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.9215, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.2602, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.5278, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown dog dog a a a a a a <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 14 ----------------------------------\n",
      "Loss :  tensor(1.9903, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7327, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7276, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.8227, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.4732, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.8624, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.0860, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.5327, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown is running across across across across across across across across\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 15 ----------------------------------\n",
      "Loss :  tensor(1.8466, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.5925, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.8311, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7877, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.3029, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7109, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.0283, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.4721, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown dog is a a running running <end> <end> <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 16 ----------------------------------\n",
      "Loss :  tensor(1.8449, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.4489, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7674, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7724, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.0326, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7161, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(2.0576, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.4376, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown dog wearing wearing black beach beach beach beach beach beach\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 17 ----------------------------------\n",
      "Loss :  tensor(1.7614, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7178, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7798, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.6636, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.4166, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7735, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.9519, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.3105, grad_fn=<NllLossBackward>)\n",
      "Prediction :   a brown dog is a a collar running <end> <end> <end> <end>\n",
      "Truth :   a brown dog wearing a black collar running across the beach\n",
      "----------------------------------- Epoch 18 ----------------------------------\n",
      "Loss :  tensor(1.7742, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.4219, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.6901, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.6944, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.0142, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.6872, grad_fn=<NllLossBackward>)\n",
      "Loss :  tensor(1.7686, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "data_folder = os.path.join('processed_data','flickr')\n",
    "embedding_len = 512  \n",
    "attention_len = 512  \n",
    "lstm_len = 512  \n",
    "caps_per_image=2\n",
    "batch_size = 32\n",
    "learning_rate = 4e-3  \n",
    "\n",
    "# Read word map\n",
    "word_map_file = os.path.join(data_folder, 'WORDMAP.json')\n",
    "with open(word_map_file, 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "\n",
    "# Decoder model\n",
    "decoder = Decoder(attention_len=attention_len,\n",
    "                    embedding_len=embedding_len,\n",
    "                    features_len=lstm_len,\n",
    "                    wordmap_len=len(word_map))\n",
    "# We need an optimiser to update the model weights\n",
    "grad_params=filter(lambda p: p.requires_grad, decoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(params=grad_params, lr=learning_rate)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Dataloaders are wrappers around datasets that help woth the learning.\n",
    "# Its not mandatory but its usefull so we might as well use it\n",
    "dataset=FlickrDataset(data_folder, 'DEV', caps_per_image)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "            FlickrDataset(data_folder, 'DEV', caps_per_image),\n",
    "            batch_size=5, )\n",
    "\n",
    "losses=[]\n",
    "weights=[]\n",
    "predictions=[]\n",
    "print('--------------------------------------------- LEARNING STARTED -------------------------------------------')\n",
    "for epoch in range(1,50):\n",
    "    print( '----------------------------------- Epoch',epoch,'----------------------------------')\n",
    "    for i,(imgs,caps,caplens) in enumerate(data_loader):\n",
    "        #print( '----------------------------------- Batch',i,'----------------------------------')\n",
    "\n",
    "        scores, caps_sorted, decode_lengths, alphas, sort_ind=decoder.forward(imgs, caps.to(dtype=torch.int64), caplens)\n",
    "        # Remove the <start> word\n",
    "        targets = caps_sorted[:, 1:]\n",
    "\n",
    "        prediction=''\n",
    "        for line in scores[0]:\n",
    "            idx=line.argmax()\n",
    "            for key in word_map.keys():\n",
    "                if word_map[key]==idx:\n",
    "                    prediction+=' '+str(key)\n",
    "        caption=''\n",
    "        for line in caps[sort_ind[0], 1:caplens[sort_ind[0]]+1]:\n",
    "            for key in word_map.keys():\n",
    "                if word_map[key]==line:\n",
    "                    caption+=' '+str(key)\n",
    "\n",
    "        # Remove timesteps that we didn't decode at, or are pads\n",
    "        # pack_padded_sequence is an easy trick to do this\n",
    "        scores, _ = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "        targets, _ = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(scores, targets)\n",
    "        #print('loss : ',loss.item())\n",
    "        decoder_optimizer.zero_grad()\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        decoder_optimizer.step()\n",
    "        print('Loss : ',loss)\n",
    "    predictions.append(prediction)\n",
    "    weights.append(alphas)    \n",
    "    #print('--------------------------------------------------------------')\n",
    "    print('Prediction : ',prediction)\n",
    "    print('Truth : ',caption)\n",
    "    #print('--------------------------------------------------------------')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "losses=np.array(losses)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.transform import resize\n",
    "from skimage import io, transform\n",
    "\n",
    "path='./raw_data/flickr_data/488416045_1c6d903fe0.jpg'\n",
    "image = io.imread(path)\n",
    "\n",
    "for i,weight in enumerate(weights):\n",
    "    plt.figure(i,figsize=(8, 6))\n",
    "    for j,word in  enumerate(weight[-1]):\n",
    "        attention=np.array(word.detach()).reshape(14,14)\n",
    "        attention = resize(attention, (224, 224))\n",
    "        plt.subplot(1,len(weight[-1]),j+1)\n",
    "        plt.imshow(image)\n",
    "        plt.subplots_adjust(hspace = .1)\n",
    "\n",
    "        plt.imshow(attention,cmap='gray', alpha=1)\n",
    "        plt.title(predictions[i].split()[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
